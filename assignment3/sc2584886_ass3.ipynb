{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh3Qjh8mRHqD"
      },
      "source": [
        "# Assignment 3: Hidden Markov Models for POS Tagging and Text Generation\n",
        "## CNG463 - Introduction to Natural Language Processing\n",
        "### METU NCC Computer Engineering | Fall 2025-26\n",
        "\n",
        "**Student Name:** S√ºleyman √áoban\n",
        "**Student ID:**  2584886\n",
        "**Due Date:** 14 December 2025 (Sunday) before midnight\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyDEnwcxRHqE"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This assignment focuses on:\n",
        "1. Building **supervised**, **unsupervised**, and **semi-supervised** HMM models for Part-of-Speech (POS) tagging\n",
        "2. Implementing **5-fold cross-validation** to evaluate model performance\n",
        "3. Comparing the three training approaches using per-tag and overall accuracy\n",
        "4. Using HMMs for **creative text generation** with temperature-based sampling\n",
        "\n",
        "**Note:** You will use the Brown corpus with universal POS tagset. Start with 5000 sentences for debugging, then run on the full corpus (or as much as Colab can handle).\n",
        "\n",
        "**Grading:**\n",
        "- Helper Functions: **10 pts**\n",
        "  - `remove_tags()`: 2 pts\n",
        "  - `evaluate_tagger()`: 5 pts\n",
        "  - Results display: 3 pts\n",
        "- Semi-supervised HMM: **20 pts**\n",
        "- 5-fold cross-validation: **25 pts**\n",
        "  - Supervised HMM: 10 pts\n",
        "  - Unsupervised HMM (Baum-Welch): 10 pts\n",
        "  - Semi-supervised HMM\n",
        "  - Evaluate and Accumulate Results: 5 pts\n",
        "- Report on Results: **5 pts**\n",
        "- Text Generation: **24 pts**\n",
        "  - `sample_state()`: 7 pts\n",
        "  - `sample_word()`: 7 pts\n",
        "  - `generate_text_from_word()`: 10 pts\n",
        "- Written Questions (4 √ó 4 pts): **16 pts**\n",
        "- **Total: 100 pts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srF42PZXRHqP"
      },
      "source": [
        "---\n",
        "\n",
        "## Pre-Submission Checklist\n",
        "\n",
        "- [ ] Name and student ID at top\n",
        "- [ ] No cells are added or removed\n",
        "- [ ] All TODO sections completed\n",
        "- [ ] All questions answered\n",
        "- [ ] Code runs without errors\n",
        "- [ ] Results tables included\n",
        "- [ ] Run All before saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq0Xw3YQRHqE"
      },
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwyLNfKaRHqE"
      },
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# NLTK for corpus and HMM\n",
        "import nltk\n",
        "from nltk.tag import hmm\n",
        "\n",
        "# Scikit-learn for cross-validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr-UNnAGRHqF"
      },
      "source": [
        "---\n",
        "\n",
        "# Task 1: HMM-based POS Tagging (72 points)\n",
        "\n",
        "In this part, you will implement three different approaches to training HMM models for POS tagging:\n",
        "1. **Supervised learning**: Uses fully labelled data\n",
        "2. **Unsupervised learning**: Uses unlabelled data with Baum-Welch algorithm\n",
        "3. **Semi-supervised learning**: Combines a small amount of labelled data with larger unlabelled data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5k13c4MRHqF"
      },
      "source": [
        "## 1.1: Load the Brown Corpus\n",
        "\n",
        "Load the Brown corpus with universal POS tagset. Start with 5000 sentences for testing, then increase to the maximum your environment can handle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb6tjNLmRHqF"
      },
      "outputs": [],
      "source": [
        "# Download required NLTK data\n",
        "from nltk.corpus import brown\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "NUM_SENTENCES = 1000  # Start with 5000 sentences and increase later\n",
        "\n",
        "all_data = list(brown.tagged_sents(tagset=\"universal\"))[:NUM_SENTENCES]\n",
        "\n",
        "print(f\"Total sentences loaded: {len(all_data)}\")\n",
        "print(f\"\\nExample sentence:\")\n",
        "print(all_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwDDP9gORHqF"
      },
      "source": [
        "## 1.2: Remove Tags (2 points)\n",
        "\n",
        "Implement the `remove_tags()` function that converts tagged sentences to untagged format required by NLTK's unsupervised training.\n",
        "\n",
        "**Input:** List of tagged sentences `[[(word, tag), ...], ...]`  \n",
        "**Output:** List of untagged sentences `[[(word, None), ...], ...]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI_9lAXTRHqF"
      },
      "outputs": [],
      "source": [
        "def remove_tags(tagged_sents):\n",
        "  untagged_data = []\n",
        "\n",
        "  # 2. Loop through every sentence in the input data\n",
        "  for sentence in tagged_sents:\n",
        "\n",
        "    # Create a temporary list for the current sentence\n",
        "    new_sentence = []\n",
        "\n",
        "    # 3. Loop through every word pair in the current sentence\n",
        "    for word, tag in sentence: # tuple unpacking\n",
        "      # Keep the word, but change the tag to None #this will unpack each tuples in a sentence and replace the tags with none\n",
        "      new_pair = (word, None)\n",
        "      new_sentence.append(new_pair)\n",
        "\n",
        "      # Add the processed sentence to our main list\n",
        "      untagged_data.append(new_sentence)\n",
        "  return untagged_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg18ezdTRHqG"
      },
      "source": [
        "## 1.3: Evaluate Tagger (5 points)\n",
        "\n",
        "Implement the `evaluate_tagger()` function that evaluates a trained tagger on test data and returns per-tag accuracy statistics.\n",
        "\n",
        "**Input:**\n",
        "- `tagger`: Trained HMM tagger\n",
        "- `test_data`: List of tagged test sentences\n",
        "\n",
        "**Output:** Dictionary with per-tag statistics `{tag: {'correct': count, 'total': count}}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLjQTbejRHqG"
      },
      "outputs": [],
      "source": [
        "def evaluate_tagger(tagger, test_data):\n",
        "\n",
        "    # 1. Initialize tag_stats as defaultdict(lambda: {'correct': 0, 'total': 0})\n",
        "    tag_stats = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
        "\n",
        "    # 2. For each sentence in test_data:\n",
        "    for sentence in test_data:\n",
        "        #    a. Extract words and true tags\n",
        "        words = [word for word, tag in sentence]\n",
        "        true_tags = [tag for word, tag in sentence]\n",
        "\n",
        "        try:\n",
        "            #    b. Use tagger.tag(words) to get predicted tags\n",
        "            predicted_pairs = tagger.tag(words)\n",
        "            predicted_tags = [tag for word, tag in predicted_pairs]\n",
        "\n",
        "            #    c. Compare true vs predicted tags\n",
        "            for true_tag, pred_tag in zip(true_tags, predicted_tags):\n",
        "\n",
        "                #    d. Update tag_stats accordingly\n",
        "                tag_stats[true_tag]['total'] += 1\n",
        "\n",
        "                # increment 'correct' if the prediction is true\n",
        "                if true_tag == pred_tag:\n",
        "                    tag_stats[true_tag]['correct'] += 1\n",
        "\n",
        "        # 3. Handle exceptions (if tagging fails, count all as incorrect)\n",
        "        except Exception as e:\n",
        "            for tag in true_tags:\n",
        "                tag_stats[tag]['total'] += 1\n",
        "\n",
        "    # 4. Return tag_stats\n",
        "    return dict(tag_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkl012"
      },
      "source": [
        "## 1.4: Semi-supervised HMM Training (20 points)\n",
        "\n",
        "Implement semi-supervised HMM training that combines a small amount of labelled data (1%) with larger unlabelled data (99%).\n",
        "\n",
        "**Steps:**\n",
        "1. Split data: 1% tagged, 99% untagged\n",
        "2. Train supervised model on 1% tagged data\n",
        "3. Use this model to initialise Baum-Welch on 99% untagged data\n",
        "4. Refine with unsupervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mno345"
      },
      "outputs": [],
      "source": [
        "def train_semi_supervised(tagged_data, percent_tagged=1.0):\n",
        "\n",
        "# 1. Calculate split index\n",
        "    total_len = len(tagged_data)\n",
        "    split_idx = int(total_len * (percent_tagged / 100.0))\n",
        "\n",
        "    #    Ensure at least 1 sentence is tagged\n",
        "    if split_idx < 1 and total_len > 0:\n",
        "        split_idx = 1\n",
        "    print(f\"Splitting: {split_idx} tagged, {total_len - split_idx} untagged.\")\n",
        "\n",
        "    # 2. Split data\n",
        "    tagged_portion = tagged_data[:split_idx]\n",
        "    untagged_portion = remove_tags(tagged_data[split_idx:])\n",
        "\n",
        "    # 3. Extract states and symbols from ALL data\n",
        "    all_states = set()\n",
        "    all_symbols = set()\n",
        "\n",
        "    for sent in tagged_data:\n",
        "        for word, tag in sent:\n",
        "            all_states.add(tag)\n",
        "            all_symbols.add(word)\n",
        "\n",
        "    # 4. Initialize trainer with states and symbols using\n",
        "    trainer = hmm.HiddenMarkovModelTrainer(\n",
        "        states=list(all_states),\n",
        "        symbols=list(all_symbols)\n",
        "    )\n",
        "\n",
        "    # 5. Train supervised model on small tagged data using trainer.train_supervised\n",
        "    print(\"Training initial supervised model\")\n",
        "    supervised_model = trainer.train_supervised(tagged_portion)\n",
        "\n",
        "    # 6. Refine with Baum-Welch on untagged data using trainer.train_unsupervised\n",
        "    if len(untagged_portion) > 0:\n",
        "        print(\"Step 2: Refining with unsupervised learning\")\n",
        "        refined_model = trainer.train_unsupervised(\n",
        "            untagged_portion,\n",
        "            model=supervised_model,\n",
        "            max_iterations=5\n",
        "        )\n",
        "        # 7. Return refined_tagger (or error if no untagged data or no tagged data)\n",
        "        return refined_model\n",
        "    else:\n",
        "        raise ValueError(\"No untagged Data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqr678"
      },
      "source": [
        "## 1.5: 5-Fold Cross-Validation (25 Points)\n",
        "\n",
        "Implement 5-fold cross-validation to train and evaluate all three models. This ensures robust performance estimates.\n",
        "\n",
        "**Steps:**\n",
        "1. Split data into 5 folds\n",
        "2. For each fold:\n",
        "   - Train\n",
        "    - supervised (`trainer.train_supervised()`)\n",
        "    - unsupervised (`trainer.train_unsupervised()`)\n",
        "    - semi-supervised models (`train_semi_supervised()`)\n",
        "   - Evaluate on test fold\n",
        "   - Accumulate results\n",
        "3. Calculate average accuracy across all folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stu901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e79c76-dffb-4388-ebef-b8342bc2205d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FOLD 0\n",
            "============================================================\n",
            "Training set: 800 sentences\n",
            "Test set: 200 sentences\n",
            "\n",
            "1. Training Unsupervised HMM (Baum-Welch)...\n",
            "iteration 0 logprob -6122213.149708354\n",
            "iteration 1 logprob -4747973.557405709\n",
            "iteration 2 logprob -4739232.009649948\n",
            "iteration 3 logprob -4730584.100365082\n",
            "iteration 4 logprob -4720077.520962452\n",
            "Unsupervised training complete\n",
            "\n",
            "2. Training Supervised HMM...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:333: RuntimeWarning: overflow encountered in cast\n",
            "  X[i, j] = self._transitions[si].logprob(self._states[j])\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:335: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:331: RuntimeWarning: overflow encountered in cast\n",
            "  P[i] = self._priors.logprob(si)\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:363: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Supervised training complete\n",
            "\n",
            "3. Training Semi-Supervised HMM (1% tagged, 99% untagged)...\n",
            "Splitting: 8 tagged, 792 untagged.\n",
            "Training initial supervised model\n",
            "Step 2: Refining with unsupervised learning\n"
          ]
        }
      ],
      "source": [
        "# Prepare for 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "# Storage for results across folds\n",
        "results = {\n",
        "    'unsupervised': defaultdict(lambda: {'correct': 0, 'total': 0}),\n",
        "    'supervised': defaultdict(lambda: {'correct': 0, 'total': 0}),\n",
        "    'semi_supervised': defaultdict(lambda: {'correct': 0, 'total': 0})\n",
        "}\n",
        "\n",
        "fold_num = 0\n",
        "\n",
        "# TODO: Complete the cross-validation loop\n",
        "\n",
        "for train_idx, test_idx in kf.split(all_data):\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"FOLD {fold_num}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    fold_num += 1\n",
        "\n",
        "    # Split data to train_data and test_data\n",
        "    train_data = [all_data[i] for i in train_idx]\n",
        "    test_data = [all_data[i] for i in test_idx]\n",
        "\n",
        "\n",
        "    print(f\"Training set: {len(train_data)} sentences\")\n",
        "    print(f\"Test set: {len(test_data)} sentences\")\n",
        "\n",
        "    # Extract all_tags and all_symbols from training data\n",
        "    current_states = set()\n",
        "    current_symbols = set()\n",
        "    for sent in train_data:\n",
        "        for word, tag in sent:\n",
        "            current_states.add(tag)\n",
        "            current_symbols.add(word)\n",
        "\n",
        "    # Convert to lists for the trainer\n",
        "    list_states = list(current_states)\n",
        "    list_symbols = list(current_symbols)\n",
        "\n",
        "    # 1. Unsupervised HMM (Baum-Welch)\n",
        "    print(\"\\n1. Training Unsupervised HMM (Baum-Welch)...\")\n",
        "    try:\n",
        "        # 1.1 Convert to untagged format\n",
        "        untagged_train = remove_tags(train_data)\n",
        "\n",
        "        # 1.2 Initialize trainer with states and symbols\n",
        "        trainer_unsup = hmm.HiddenMarkovModelTrainer(states=list_states, symbols=list_symbols)\n",
        "\n",
        "        # 1.3 Train unsupervised\n",
        "        tagger_unsup = trainer_unsup.train_unsupervised(untagged_train, max_iterations=5)\n",
        "\n",
        "        # 1.4 Evaluate unsupervised tagger and update the results dict\n",
        "        fold_stats = evaluate_tagger(tagger_unsup, test_data)\n",
        "\n",
        "        # Accumulate results\n",
        "        for tag, counts in fold_stats.items():\n",
        "            results['unsupervised'][tag]['correct'] += counts['correct']\n",
        "            results['unsupervised'][tag]['total'] += counts['total']\n",
        "\n",
        "        print(\"Unsupervised training complete\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Unsupervised training failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # 2. Supervised HMM\n",
        "    print(\"\\n2. Training Supervised HMM...\")\n",
        "    try:\n",
        "        # 1.1 Initialize trainer with states and symbols\n",
        "        trainer_sup = hmm.HiddenMarkovModelTrainer(states=list_states, symbols=list_symbols)\n",
        "\n",
        "        # 1.2 Train supervised\n",
        "        tagger_sup = trainer_sup.train_supervised(train_data)\n",
        "\n",
        "        # 1.3 Evaluate supervised tagger and update the results dict\n",
        "        fold_stats = evaluate_tagger(tagger_sup, test_data)\n",
        "\n",
        "        # Accumulate results\n",
        "        for tag, counts in fold_stats.items():\n",
        "            results['supervised'][tag]['correct'] += counts['correct']\n",
        "            results['supervised'][tag]['total'] += counts['total']\n",
        "\n",
        "        print(\"Supervised training complete\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Supervised training failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # 3. Semi-supervised HMM (1% tagged, 99% untagged)\n",
        "    print(\"\\n3. Training Semi-Supervised HMM (1% tagged, 99% untagged)...\")\n",
        "    try:\n",
        "        # 1.1 Train semi-supervised\n",
        "        tagger_semi_sup = train_semi_supervised(train_data, percent_tagged=1.0)\n",
        "\n",
        "        # 1.3 Evaluate semi-supervised tagger and update the results dict\n",
        "        fold_stats = evaluate_tagger(tagger_semi_sup, test_data)\n",
        "\n",
        "        # Accumulate results\n",
        "        for tag, counts in fold_stats.items():\n",
        "            results['semi_supervised'][tag]['correct'] += counts['correct']\n",
        "            results['semi_supervised'][tag]['total'] += counts['total']\n",
        "\n",
        "        print(\"Semi-supervised training complete\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Semi-supervised training failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZLYOOQPz-Si"
      },
      "source": [
        "**Question 1.1:** In an unsupervised HMM with 12 hidden states, you replace the intended PoS tags with meaningless labels like S1‚ÄìS12. How would this change affect the model‚Äôs learned behaviour and its evaluation accuracy? (4 points, 3-4 sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc9EPblW0JgN"
      },
      "source": [
        "Model's learning behaviour wouldn't change because it does not learn by labels, it learns by discovering patterns based on the sequence statistics and relations within the data. However, evaluation accuracy would become impossible to calculate directly because if we do not correctly map the meaningless labels we wouldn't know which one was noun or which one was verb. But if the mapping is fine then the evaluation accuracy would be same as the unsupervised HMM trained with meaningful labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "question1"
      },
      "source": [
        "**Question 1.2:** You initialize a semi-supervised HMM with a fully supervised model and then run Baum‚ÄìWelch only on unlabeled data. How can this additional unsupervised training change the model‚Äôs behaviour and accuracy? (4 points, 3-4 sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kZZAfPOcRtr"
      },
      "source": [
        "The additional unsupervised training allows the model to refine its transition and emission probabilities on a much larger corpus (labeled: %1 and unlabelled: %99). And this helped the model to learn much more usage patterns and handle unseen words better. However, since Baum-Welch prioritizes data likelihood rather than label correctness the models learned states may change from the initial supervised learning which may reduce the true Pos tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "question2"
      },
      "source": [
        "**Question 1.3:** Consider the following four changes to an unsupervised or semi-supervised HMM for PoS tagging. For each one, state whether it would make training faster, slower, or have no significant effect, and justify your choice in one sentence. (4 points, 4 sentences)\n",
        "- Reducing the number of hidden states from 12 to 6.\n",
        "- Initializing the model with a fully supervised HMM instead of random parameters.\n",
        "- Increasing the size of the unlabeled corpus by a factor of 5.\n",
        "- Replacing full EM with a fixed small number of EM iterations (e.g., exactly 3 passes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMu3eWDRcSUd"
      },
      "source": [
        "1) Training would be faster because fewer states mean fewer probability calculations.\n",
        "\n",
        "2) Training would be faster because starting with better initial model allows Baum-Welch to converge faster (in fewer iterations), as the model will start closer to optimal parameters rather than exploring random starting points.\n",
        "\n",
        "3) Training would be slower because processing 5 times more sentences per iteration directly increases computational cost.\n",
        "\n",
        "4) Training would be faster because limiting iterations to 3 forces the model to stop before convergence, which eliminates the additional iterations.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwx234"
      },
      "source": [
        "## 1.6: Display Results (5 points)\n",
        "\n",
        "Display the average across folds results in a formatted table showing\n",
        "- tag frequency (%)\n",
        "- per-tag accuracy (%)\n",
        "- overall accuracy (%)\n",
        "\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "for all three models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yza567"
      },
      "outputs": [],
      "source": [
        "# iterate through each model\n",
        "model_order = ['supervised', 'unsupervised', 'semi_supervised']\n",
        "\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"{'FINAL EVALUATION RESULTS (Average across 5 Folds)':^80}\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "for model_name in model_order:\n",
        "    # Check if we have data for a model\n",
        "    if model_name not in results:\n",
        "        continue\n",
        "\n",
        "    data = results[model_name]\n",
        "\n",
        "    # Calculate statistics\n",
        "    total_correct = sum(tag_data['correct'] for tag_data in data.values())\n",
        "    total_tokens = sum(tag_data['total'] for tag_data in data.values())\n",
        "\n",
        "    # Avoid division by zero\n",
        "    overall_accuracy = (total_correct / total_tokens * 100) if total_tokens > 0 else 0.0\n",
        "\n",
        "    print(f\"MODEL: {model_name}\")\n",
        "    print(f\"{'-'*45}\")\n",
        "    print(f\"{'TAG':<12} | {'FREQ (%)':<12} | {'ACCURACY (%)':<12}\")\n",
        "    print(f\"{'-'*45}\")\n",
        "\n",
        "    # Calculate per-tag statistics\n",
        "    sorted_tags = sorted(data.keys())\n",
        "\n",
        "    for tag in sorted_tags:\n",
        "        stats = data[tag]\n",
        "        tag_total = stats['total']\n",
        "        tag_correct = stats['correct']\n",
        "\n",
        "        if tag_total > 0:\n",
        "            # How often does the tag appears\n",
        "            frequency = (tag_total / total_tokens) * 100\n",
        "\n",
        "            # what is our correct tag rate\n",
        "            accuracy = (tag_correct / tag_total) * 100\n",
        "\n",
        "            print(f\"{tag:<12} | {frequency:>10.2f}% | {accuracy:>10.2f}%\")\n",
        "        else:\n",
        "            print(f\"{tag:<12} | {'0.00%':>10} | {'N/A':>10}\")\n",
        "\n",
        "    print(f\"{'-'*45}\")\n",
        "    print(f\"{'OVERALL':<12} | {'100.00%':>10} | {overall_accuracy:>10.2f}%\")\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcd890"
      },
      "source": [
        "## 1.7: Sample Predictions\n",
        "\n",
        "Test the models on sample sentences to see how it performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efg123"
      },
      "outputs": [],
      "source": [
        "# Print sample predictions from the last fold\n",
        "print(\"Sample predictions from last fold:\")\n",
        "sample_sentences = [\n",
        "    \"Today is a good day .\",\n",
        "    \"Joe met Joanne in Delhi .\",\n",
        "    \"Time flies like an arrow .\",\n",
        "    \"The good , the bad , the ugly went to a bar .\"\n",
        "]\n",
        "\n",
        "print(f\"{'='*10} Spervised HMM Tagger {'='*10}\")\n",
        "for sent in sample_sentences:\n",
        "    try:\n",
        "        tagged = tagger_sup.tag(sent.split())\n",
        "        print(f\"  {sent}\")\n",
        "        print(f\"  ‚Üí {tagged}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"  {sent}\")\n",
        "        print(f\"ERROR: Tagging failed: {e}\\n\")\n",
        "\n",
        "print(f\"{'='*10} Unspervised HMM Tagger {'='*10}\")\n",
        "for sent in sample_sentences:\n",
        "    try:\n",
        "        tagged = tagger_unsup.tag(sent.split())\n",
        "        print(f\"  {sent}\")\n",
        "        print(f\"  ‚Üí {tagged}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"  {sent}\")\n",
        "        print(f\"ERROR: Tagging failed: {e}\\n\")\n",
        "\n",
        "print(f\"{'='*10} Semi-spervised HMM Tagger {'='*10}\")\n",
        "for sent in sample_sentences:\n",
        "    try:\n",
        "        tagged = tagger_semi_sup.tag(sent.split())\n",
        "        print(f\"  {sent}\")\n",
        "        print(f\"  ‚Üí {tagged}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"  {sent}\")\n",
        "        print(f\"ERROR: Tagging failed: {e}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part2_header"
      },
      "source": [
        "---\n",
        "\n",
        "# Task 2: Text Generation with HMMs (24 points)\n",
        "\n",
        "In this part, you will use a trained HMM to generate text. The idea is to sample from the learned transition and emission probabilities to create new sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train_gen_model"
      },
      "source": [
        "## 2.1: Train HMM Model for Generation\n",
        "\n",
        "First, train a supervised HMM model on the Brown corpus for text generation. We'll normalise words to lowercase for better generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_model_gen"
      },
      "outputs": [],
      "source": [
        "def train_hmm_model(num_sentences=5000):\n",
        "    \"\"\"Train an HMM model on Brown corpus for text generation\"\"\"\n",
        "    print(\"Loading Brown corpus...\")\n",
        "    tagged_sents = list(brown.tagged_sents(tagset=\"universal\"))[:num_sentences]\n",
        "\n",
        "    print(f\"Training HMM on {len(tagged_sents)} sentences...\")\n",
        "\n",
        "    # Extract states and symbols\n",
        "    all_tags = set()\n",
        "    all_symbols = set()\n",
        "    for sent in tagged_sents:\n",
        "        for word, tag in sent:\n",
        "            all_tags.add(tag)\n",
        "            all_symbols.add(word.lower())  # Normalise to lowercase\n",
        "\n",
        "    # Normalise training data to lowercase\n",
        "    normalized_sents = []\n",
        "    for sent in tagged_sents:\n",
        "        normalized_sents.append([(word.lower(), tag) for word, tag in sent])\n",
        "\n",
        "    # Train the model\n",
        "    trainer = hmm.HiddenMarkovModelTrainer(\n",
        "        states=list(all_tags),\n",
        "        symbols=list(all_symbols)\n",
        "    )\n",
        "    tagger = trainer.train_supervised(normalized_sents)\n",
        "    print(\"Training complete!\")\n",
        "    return tagger\n",
        "\n",
        "# Train the model\n",
        "tagger_gen = train_hmm_model(num_sentences=20000)\n",
        "\n",
        "# Show model statistics\n",
        "print(f\"\\nModel Statistics:\")\n",
        "print(f\"  - Number of states (POS tags): {len(tagger_gen._states)}\")\n",
        "print(f\"  - Number of symbols (words): {len(tagger_gen._symbols)}\")\n",
        "print(f\"  - States: {', '.join(sorted(tagger_gen._states))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sample_state_header"
      },
      "source": [
        "## 2.2: Implement State Sampling (7 points)\n",
        "\n",
        "Implement the `sample_state()` function that samples the next POS tag based on transition probabilities.\n",
        "\n",
        "**Temperature parameter:** Controls randomness\n",
        "- Lower temperature (e.g., 0.5): More conservative, follows high-probability transitions\n",
        "- Higher temperature (e.g., 2.0): More creative, explores diverse transitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sample_state_code"
      },
      "outputs": [],
      "source": [
        "def sample_state(tagger, current_state, temperature=1.0):\n",
        "\n",
        "    # 1. Get all possible states from tagger._states\n",
        "    states = list(tagger._states)\n",
        "\n",
        "    # 2. Get transition probability from current state\n",
        "    log_probs = np.array([tagger._transitions[current_state].logprob(state) for state in states])\n",
        "\n",
        "    # 3. Apply temperature scaling\n",
        "    if temperature <= 0: temperature = 1e-10\n",
        "    scaled_log_probs = log_probs / temperature\n",
        "\n",
        "    # 4. Convert from log2 probabilities to regular probabilities\n",
        "    probs = 2.0 ** scaled_log_probs\n",
        "\n",
        "    # 5. Normalise probabilities to sum to 1\n",
        "    total_prob = np.sum(probs)\n",
        "\n",
        "    if total_prob == 0:\n",
        "        probs = np.ones(len(states)) / len(states)\n",
        "    else:\n",
        "        probs = probs / total_prob\n",
        "\n",
        "    # 6. Sample using np.random.choice(states, p=probs)\n",
        "    next_state = np.random.choice(states, p=probs)\n",
        "\n",
        "    return next_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sample_word_header"
      },
      "source": [
        "## 2.3: Implement Word Sampling (7 points)\n",
        "\n",
        "Implement the `sample_word()` function that samples a word given a POS tag based on emission probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sample_word_code"
      },
      "outputs": [],
      "source": [
        "def sample_word(tagger, state, temperature=1.0):\n",
        "\n",
        "# 1. Get all possible symbols (words) from tagger._symbols\n",
        "    symbols = list(tagger._symbols)\n",
        "\n",
        "    # 2. For each symbol, get emission probability from state\n",
        "    probs = np.array([tagger._outputs[state].logprob(symbol) for symbol in symbols])\n",
        "\n",
        "    # 3. Apply temperature scaling: probs = probs / temperature\n",
        "    if temperature <= 0: temperature = 1e-10\n",
        "    probs = probs / temperature\n",
        "\n",
        "    # 4. Convert from log2 probabilities to regular probabilities: 2 ** probs\n",
        "    probs = 2.0 ** probs\n",
        "\n",
        "    # 5. Handle infinities (words with zero probability) using np.nan_to_num\n",
        "    probs = np.nan_to_num(probs)\n",
        "\n",
        "    # 6. Normalise probabilities to sum to 1\n",
        "    total_prob = np.sum(probs)\n",
        "\n",
        "    #    (if all are zero, use uniform distribution)\n",
        "    if total_prob == 0:\n",
        "        probs = np.ones(len(symbols)) / len(symbols)\n",
        "    else:\n",
        "        probs = probs / total_prob\n",
        "\n",
        "    # 7. Sample using np.random.choice(symbols, p=probs)\n",
        "    word = np.random.choice(symbols, p=probs)\n",
        "\n",
        "    return word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gen_text_header"
      },
      "source": [
        "## 2.4: Implement Text Generation (10 points)\n",
        "\n",
        "Implement the `generate_text_from_word()` function that generates text starting from a given word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gen_text_code"
      },
      "outputs": [],
      "source": [
        "def generate_text_from_word(tagger, start_word, length=20, temperature=1.0):\n",
        "\n",
        "    # 1. Normalise start_word to lowercase\n",
        "    current_word = start_word.lower()\n",
        "\n",
        "    # 2. Check if start_word is in vocabulary (tagger._symbols)\n",
        "    vocab = set(tagger._symbols)\n",
        "\n",
        "    # - If not, find similar words or use random word\n",
        "    if current_word not in vocab:\n",
        "        print(f\"Warning: '{current_word}' not in vocabulary. Using a random word.\")\n",
        "        current_word = random.choice(list(vocab))\n",
        "\n",
        "    # 3. Initialise generated list with start_word\n",
        "    generated_list = [current_word]\n",
        "\n",
        "    # 4. Infer the most likely tag for start_word:\n",
        "    best_state = None\n",
        "    max_log_prob = -float('inf')\n",
        "\n",
        "    #    - For each state, get emission probability\n",
        "    #    - Choose state with highest probability\n",
        "    for state in tagger._states:\n",
        "        prob = tagger._outputs[state].logprob(current_word)\n",
        "        if prob > max_log_prob:\n",
        "            max_log_prob = prob\n",
        "            best_state = state\n",
        "\n",
        "    if best_state is None:\n",
        "        best_state = random.choice(list(tagger._states))\n",
        "\n",
        "    current_state = best_state\n",
        "\n",
        "    # 5. Generate subsequent words in a loop\n",
        "    for _ in range(length - 1):\n",
        "\n",
        "        #    - Sample next state using sample_state()\n",
        "        next_state = sample_state(tagger, current_state, temperature)\n",
        "\n",
        "        #    - Sample word from that state using sample_word()\n",
        "        next_word = sample_word(tagger, next_state, temperature)\n",
        "\n",
        "        #    - Append word to generated list\n",
        "        generated_list.append(next_word)\n",
        "        current_state = next_state\n",
        "\n",
        "    # 6. Return generated list\n",
        "    return generated_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test_gen_header"
      },
      "source": [
        "## 2.6: Test Text Generation\n",
        "\n",
        "Now test your text generation functions with different starting words and temperatures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_gen_code"
      },
      "outputs": [],
      "source": [
        "# Test with example words\n",
        "print(\"=\"*70)\n",
        "print(\"EXAMPLE GENERATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "example_words = [\"the\", \"dog\", \"running\", \"beautiful\", \"computer\", \"yesterday\"]\n",
        "\n",
        "for word in example_words:\n",
        "    print(f\"\\n--- Starting with '{word}' ---\")\n",
        "    try:\n",
        "        words = generate_text_from_word(tagger_gen, word, length=15, temperature=1.0)\n",
        "        print(\" \".join(words))\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_temp_code"
      },
      "outputs": [],
      "source": [
        "# Test different temperatures\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEMPERATURE COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "test_word = \"the\"\n",
        "temperatures = [(\"Conservative\", 0.5), (\"Balanced\", 1.0), (\"Creative\", 2.0)]\n",
        "\n",
        "for temp_name, temp_value in temperatures:\n",
        "    print(f\"\\n{temp_name} (temp={temp_value}):\")\n",
        "    words = generate_text_from_word(tagger_gen, test_word, length=20, temperature=temp_value)\n",
        "    print(\" \".join(words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "question3"
      },
      "source": [
        "**Question 2.1:** How does the temperature parameter affect the quality and creativity of generated text? Provide two specific examples from your outputs. (4 points, 5-6 sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "answer3"
      },
      "source": [
        "**[YOUR ANSWER HERE]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdf_header"
      },
      "source": [
        "# Convert Your Colab Notebook to PDF\n",
        "\n",
        "### Step 1: Download Your Notebook\n",
        "- Go to **File ‚Üí Download ‚Üí Download .ipynb**\n",
        "- Save the file to your computer\n",
        "\n",
        "### Step 2: Upload to Colab\n",
        "- Click the **üìÅ folder icon** on the left sidebar\n",
        "- Click the **upload button**\n",
        "- Select your downloaded .ipynb file\n",
        "- Wait for the upload to complete\n",
        "\n",
        "### Step 3: Run the Code Below\n",
        "- **Uncomment the cell below** and run the cell\n",
        "- This will take about 1-2 minutes to install required packages\n",
        "\n",
        "### Step 4: Enter Notebook Name\n",
        "- When prompted, type your notebook name (e.g.`gs_000000_as2.ipynb`)\n",
        "- Press Enter\n",
        "\n",
        "### The PDF will automatically download to your computer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdf_code"
      },
      "outputs": [],
      "source": [
        "# # Install required packages (this takes about 30 seconds)\n",
        "# print(\"Installing PDF converter... please wait...\")\n",
        "# !apt-get update -qq\n",
        "# !apt-get install -y texlive-xetex texlive-fonts-recommended texlive-plain-generic pandoc > /dev/null 2>&1\n",
        "# !pip install -q nbconvert\n",
        "\n",
        "# print(\"\\n\" + \"=\"*50)\n",
        "# print(\"COLAB NOTEBOOK TO PDF CONVERTER\")\n",
        "# print(\"=\"*50)\n",
        "# print(\"\\nSTEP 1: Download your notebook\")\n",
        "# print(\"- Go to File ‚Üí Download ‚Üí Download .ipynb\")\n",
        "# print(\"- Save it to your computer\")\n",
        "# print(\"\\nSTEP 2: Upload it here\")\n",
        "# print(\"- Click the folder icon on the left (üìÅ)\")\n",
        "# print(\"- Click the upload button and select your .ipynb file\")\n",
        "# print(\"- Wait for upload to complete\")\n",
        "# print(\"\\nSTEP 3: Enter the filename below\")\n",
        "# print(\"=\"*50)\n",
        "\n",
        "# # Get notebook name from user\n",
        "# notebook_name = input(\"\\nEnter your notebook name: \")\n",
        "\n",
        "# # Add .ipynb if missing\n",
        "# if not notebook_name.endswith('.ipynb'):\n",
        "#     notebook_name += '.ipynb'\n",
        "\n",
        "# import os\n",
        "# notebook_path = f'/content/{notebook_name}'\n",
        "\n",
        "# # Check if file exists\n",
        "# if not os.path.exists(notebook_path):\n",
        "#     print(f\"\\n‚ö† Error: '{notebook_name}' not found in /content/\")\n",
        "#     print(\"\\nMake sure you uploaded the file using the folder icon (üìÅ) on the left!\")\n",
        "# else:\n",
        "#     print(f\"\\n‚úì Found {notebook_name}\")\n",
        "#     print(\"Converting to PDF... this may take 1-2 minutes...\\n\")\n",
        "\n",
        "#     # Convert the notebook to PDF\n",
        "#     !jupyter nbconvert --to pdf \"{notebook_path}\"\n",
        "\n",
        "#     # Download the PDF\n",
        "#     from google.colab import files\n",
        "#     pdf_name = notebook_name.replace('.ipynb', '.pdf')\n",
        "#     pdf_path = f'/content/{pdf_name}'\n",
        "\n",
        "#     if os.path.exists(pdf_path):\n",
        "#         print(\"‚úì SUCCESS! Downloading your PDF now...\")\n",
        "#         files.download(pdf_path)\n",
        "#         print(\"\\n‚úì Done! Check your downloads folder.\")\n",
        "#     else:\n",
        "#         print(\"‚ö† Error: Could not create PDF\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}